{"cells":[{"cell_type":"markdown","metadata":{"id":"khOEnYJB6wWu"},"source":["# 5.1. 层和块"]},{"cell_type":"markdown","metadata":{"id":"pcnkusMq6-3y"},"source":["从编程的角度来看，块由类（class）表示。它的任何子类都必须定义一个将其输入转换为输出的前向传播函数，并且必须存储任何必需的参数。注意，有些块不需要任何参数。"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1652217461712,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"2D7Ovm4I6cPe","outputId":"42d49b04-5f10-4575-daec-9dcf16a55fd5"},"outputs":[{"data":{"text/plain":["tensor([[ 0.1224, -0.0566,  0.0106, -0.1346,  0.1959, -0.0520,  0.1915, -0.1686,\n","          0.0354,  0.1326],\n","        [ 0.2215, -0.1561, -0.0190, -0.0391,  0.1200, -0.0208,  0.1896, -0.1305,\n","          0.0132,  0.1075]], grad_fn=<AddmmBackward0>)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n","\n","X = torch.rand(2, 20)\n","net(X)"]},{"cell_type":"markdown","metadata":{"id":"WruyTFNI7QD8"},"source":["在这个例子中，我们通过实例化nn.Sequential来构建我们的模型，层的执行顺序是作为参数传递的。简而言之，nn.Sequential定义了一种特殊的Module，即在PyTorch中表示一个块的类，它维护了一个由Module组成的有序列表。"]},{"cell_type":"markdown","metadata":{"id":"k2G70eVN7VDY"},"source":["## 5.1.1. 自定义块"]},{"cell_type":"markdown","metadata":{"id":"h_s02O337Z_z"},"source":["在实现我们自定义块之前，我们简要总结一下每个块必须提供的基本功能：\n","\n","将输入数据作为其前向传播函数的参数。\n","\n","通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。\n","\n","计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。\n","\n","存储和访问前向传播计算所需的参数。\n","\n","根据需要初始化模型参数。"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MGfUeeoU7GJT"},"outputs":[],"source":["class MLP(nn.Module):\n","    # 用模型参数声明层。这里，我们声明两个全连接的层\n","    def __init__(self):\n","        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n","        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n","        super().__init__()\n","        self.hidden = nn.Linear(20, 256)  # 隐藏层\n","        self.out = nn.Linear(256, 10)  # 输出层\n","\n","    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n","    def forward(self, X):\n","        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。\n","        return self.out(F.relu(self.hidden(X)))"]},{"cell_type":"markdown","metadata":{"id":"1382g_i58H4Z"},"source":["我们首先看一下前向传播函数，它以X作为输入，计算带有激活函数的隐藏表示，并输出其未规范化的输出值。在这个MLP实现中，两个层都是实例变量。要了解这为什么是合理的，可以想象实例化两个多层感知机（net1和net2），并根据不同的数据对它们进行训练。\n","\n","注意一些关键细节：首先，我们定制的__init__函数通过super().__init__()调用父类的__init__函数，省去了重复编写模版代码的痛苦。然后，我们实例化两个全连接层，分别为self.hidden和self.out。注意，除非我们实现一个新的运算符，否则我们不必担心反向传播函数或参数初始化，系统将自动生成这些。"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652217461882,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"HTGt8srS8HXd","outputId":"56ffab24-6b55-4e3d-920c-1143d797f0bf"},"outputs":[{"data":{"text/plain":["tensor([[-0.0804,  0.0408,  0.0985,  0.2034, -0.0351, -0.0908,  0.0066,  0.0723,\n","          0.1229, -0.1673],\n","        [-0.0463,  0.0307,  0.0935,  0.1393, -0.1273,  0.0362, -0.2173,  0.1306,\n","          0.0048, -0.1392]], grad_fn=<AddmmBackward0>)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["net = MLP()\n","net(X)"]},{"cell_type":"markdown","metadata":{"id":"rlSJnvXx8kAt"},"source":["## 5.1.2. 顺序块"]},{"cell_type":"markdown","metadata":{"id":"zmFopvC49D9e"},"source":["现在我们可以更仔细地看看Sequential类是如何工作的，回想一下Sequential的设计是为了把其他模块串起来。为了构建我们自己的简化的MySequential，我们只需要定义两个关键函数：\n","\n","一种将块逐个追加到列表中的函数。\n","\n","一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0J55VCM18c7H"},"outputs":[],"source":["class MySequential(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        for idx, module in enumerate(args):\n","            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n","            # 变量_modules中。module的类型是OrderedDict\n","            self._modules[str(idx)] = module\n","\n","    def forward(self, X):\n","        # OrderedDict保证了按照成员添加的顺序遍历它们\n","        for block in self._modules.values():\n","            X = block(X)\n","        return X"]},{"cell_type":"markdown","metadata":{"id":"lOZ1sN34-AEN"},"source":["__init__函数将每个模块逐个添加到有序字典_modules中。你可能会好奇为什么每个Module都有一个_modules属性？以及为什么我们使用它而不是自己定义一个Python列表？简而言之，_modules的主要优点是：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块。"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652217461882,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"rWtPR0cX-CoM","outputId":"5eb4e866-da67-4c60-ba4f-cb5ccea40415"},"outputs":[{"data":{"text/plain":["tensor([[-0.0624, -0.1550,  0.1764,  0.1065,  0.0060,  0.1179, -0.2555, -0.0184,\n","         -0.1361,  0.0062],\n","        [ 0.0569, -0.1107,  0.1383,  0.0481,  0.0330,  0.1225, -0.2511,  0.0499,\n","         -0.1867, -0.0114]], grad_fn=<AddmmBackward0>)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n","net(X)"]},{"cell_type":"markdown","metadata":{"id":"k8MTTy89A-8E"},"source":["## 5.1.3. 在前向传播函数中执行代码"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2BdciZueA5Jt"},"outputs":[],"source":["class FixedHiddenMLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n","        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n","        self.linear = nn.Linear(20, 20)\n","\n","    def forward(self, X):\n","        X = self.linear(X)\n","        # 使用创建的常量参数以及relu和mm函数\n","        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n","        # 复用全连接层。这相当于两个全连接层共享参数\n","        X = self.linear(X)\n","        # 控制流\n","        while X.abs().sum() > 1:\n","            X /= 2\n","        return X.sum()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652217461883,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"DxX63H8zBB2U","outputId":"d3d59d55-ad1c-4d0a-8e2f-77335f4dbf59"},"outputs":[{"data":{"text/plain":["tensor(0.1363, grad_fn=<SumBackward0>)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["net = FixedHiddenMLP()\n","net(X)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652217461883,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"HxYuYcmOBIVj","outputId":"a01deaef-45c4-4ab3-fd77-c437b84253df"},"outputs":[{"data":{"text/plain":["tensor(-0.0033, grad_fn=<SumBackward0>)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["class NestMLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n","                                 nn.Linear(64, 32), nn.ReLU())\n","        self.linear = nn.Linear(32, 16)\n","\n","    def forward(self, X):\n","        return self.linear(self.net(X))\n","\n","chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n","chimera(X)"]},{"cell_type":"markdown","metadata":{"id":"VobwSFfnBPO0"},"source":["# 5.2. 参数管理"]},{"cell_type":"markdown","metadata":{"id":"wB0N9vIzK64o"},"source":["访问参数，用于调试、诊断和可视化。\n","\n","参数初始化。\n","\n","在不同模型组件间共享参数。"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652217462026,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"WvzbrEEmBKZX","outputId":"bc666b64-f51a-494b-d7c9-f0045275d3c0"},"outputs":[{"data":{"text/plain":["tensor([[ 0.0640],\n","        [-0.1426]], grad_fn=<AddmmBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torch import nn\n","\n","net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n","X = torch.rand(size=(2, 4))\n","net(X)"]},{"cell_type":"markdown","metadata":{"id":"pgar33ZxK_5v"},"source":["## 5.2.1. 参数访问"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652217462027,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"de5LgmRRKFdL","outputId":"e2bffb4b-f017-4e83-d180-4d9c6475cea9"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('weight', tensor([[-0.1600,  0.3472, -0.3386,  0.0240, -0.3449, -0.0036, -0.0067, -0.3066]])), ('bias', tensor([-0.2124]))])\n"]}],"source":["print(net[2].state_dict())"]},{"cell_type":"markdown","metadata":{"id":"7ja_hYvzLTpm"},"source":["输出的结果告诉我们一些重要的事情：首先，这个全连接层包含两个参数，分别是该层的权重和偏置。两者都存储为单精度浮点数（float32）。注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。"]},{"cell_type":"markdown","metadata":{"id":"lw9TO7keLYDz"},"source":["### 5.2.1.1. 目标参数"]},{"cell_type":"markdown","metadata":{"id":"41a64aQFLwn_"},"source":["下面的代码从第二个全连接层（即第三个神经网络层）提取偏置，提取后返回的是一个参数类实例，并进一步访问该参数的值。"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652217462027,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"OXObdg6HLB3a","outputId":"c71d57d6-448c-4270-ee56-54b2f374db08"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.nn.parameter.Parameter'>\n","Parameter containing:\n","tensor([-0.2124], requires_grad=True)\n","tensor([-0.2124])\n"]}],"source":["print(type(net[2].bias))\n","print(net[2].bias)\n","print(net[2].bias.data)"]},{"cell_type":"markdown","metadata":{"id":"dNlFG-UNL1aU"},"source":["参数是复合的对象，包含值、梯度和额外信息。这就是我们需要显式参数值的原因。除了值之外，我们还可以访问每个参数的梯度。在上面这个网络中，由于我们还没有调用反向传播，所以参数的梯度处于初始状态。"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652217462028,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"DyYycpt8LaWT","outputId":"2ec5ea28-7c52-49df-9e4d-6bcf0b9bccc3"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["net[2].weight.grad == None"]},{"cell_type":"markdown","metadata":{"id":"BzTlevENL7Ei"},"source":["### 5.2.1.2. 一次性访问所有参数"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652217462028,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"pacAA608L5EO","outputId":"e5b35669-ee11-4dcd-8675-69bb2493b240"},"outputs":[{"name":"stdout","output_type":"stream","text":["('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n","('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"]}],"source":["print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n","print(*[(name, param.shape) for name, param in net.named_parameters()])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652217462029,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"fQTaLZKjMAHi","outputId":"1fb35fa7-2eb4-4030-ee61-229567ba5074"},"outputs":[{"data":{"text/plain":["tensor([-0.2124])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["net.state_dict()['2.bias'].data"]},{"cell_type":"markdown","metadata":{"id":"p4BWyLF8MHrS"},"source":["### 5.2.1.3. 从嵌套块收集参数"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1652217462029,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"FFrTnJaxMGFc","outputId":"784a4bee-16fc-4adf-d99a-1bd177ea50e3"},"outputs":[{"data":{"text/plain":["tensor([[0.3093],\n","        [0.3093]], grad_fn=<AddmmBackward0>)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["def block1():\n","    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n","                         nn.Linear(8, 4), nn.ReLU())\n","\n","def block2():\n","    net = nn.Sequential()\n","    for i in range(4):\n","        # 在这里嵌套\n","        net.add_module(f'block {i}', block1())\n","    return net\n","\n","rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n","rgnet(X)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1652217470484,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"YJu68gVDMMzj","outputId":"0f6dd294-851b-4e63-baeb-d868041a532b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Sequential(\n","    (block 0): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 1): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 2): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 3): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","  )\n","  (1): Linear(in_features=4, out_features=1, bias=True)\n",")\n"]}],"source":["print(rgnet)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1652217480028,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"ZFuasb-d1dxW","outputId":"595abda5-555b-4cb4-8de9-7144f77b1a9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Sequential(\n","    (block 0): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 1): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 2): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","    (block 3): Sequential(\n","      (0): Linear(in_features=4, out_features=8, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=8, out_features=4, bias=True)\n","      (3): ReLU()\n","    )\n","  )\n","  (1): Linear(in_features=4, out_features=1, bias=True)\n",")\n"]}],"source":["print(rgnet)"]},{"cell_type":"markdown","metadata":{"id":"4YDoczJQ1iPH"},"source":["## 5.2.2. 参数初始化"]},{"cell_type":"markdown","metadata":{"id":"LsUGFRc21nNP"},"source":["### 5.2.2.1. 内置初始化"]},{"cell_type":"markdown","metadata":{"id":"SPxVJX_PINMv"},"source":["让我们首先调用内置的初始化器。下面的代码将所有权重参数初始化为标准差为0.01的高斯随机变量，且将偏置参数设置为0。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1652217518952,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"VQkubN0h1gGt","outputId":"d75c27d7-b970-4aba-916a-0f8b143e9cbd"},"outputs":[{"data":{"text/plain":["(tensor([-0.0019,  0.0167,  0.0070,  0.0100]), tensor(0.))"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["def init_normal(m):\n","    if type(m) == nn.Linear:\n","        nn.init.normal_(m.weight, mean=0, std=0.01)\n","        nn.init.zeros_(m.bias)\n","net.apply(init_normal)\n","net[0].weight.data[0], net[0].bias.data[0]"]},{"cell_type":"markdown","metadata":{"id":"Mbta1MRAIVNp"},"source":["我们还可以将所有参数初始化为给定的常数，比如初始化为1。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1652217553993,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"OaEHcMqn1pmy","outputId":"d81707c7-7d3b-4b45-8e3c-30bc6d5fe892"},"outputs":[{"data":{"text/plain":["(tensor([1., 1., 1., 1.]), tensor(0.))"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["def init_constant(m):\n","    if type(m) == nn.Linear:\n","        nn.init.constant_(m.weight, 1)\n","        nn.init.zeros_(m.bias)\n","net.apply(init_constant)\n","net[0].weight.data[0], net[0].bias.data[0]"]},{"cell_type":"markdown","metadata":{"id":"AiN5LHTNIYix"},"source":["我们还可以对某些块应用不同的初始化方法。例如，下面我们使用Xavier初始化方法初始化第一个神经网络层，然后将第三个神经网络层初始化为常量值42。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1652217560583,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"Lr8-ZRMc1yKq","outputId":"ccbd470a-c754-454f-99ff-cf3a0bfe13a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0.0108, -0.0590, -0.2855,  0.4665])\n","tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"]}],"source":["def xavier(m):\n","    if type(m) == nn.Linear:\n","        nn.init.xavier_uniform_(m.weight)\n","def init_42(m):\n","    if type(m) == nn.Linear:\n","        nn.init.constant_(m.weight, 42)\n","\n","net[0].apply(xavier)\n","net[2].apply(init_42)\n","print(net[0].weight.data[0])\n","print(net[2].weight.data)"]},{"cell_type":"markdown","metadata":{"id":"ERYMzoR211v9"},"source":["### 5.2.2.2. 自定义初始化"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1652217575850,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"lprP4mqp1zxQ","outputId":"b90024f3-9076-4ab4-a2ec-302d1254a401"},"outputs":[{"name":"stdout","output_type":"stream","text":["Init weight torch.Size([8, 4])\n","Init weight torch.Size([1, 8])\n"]},{"data":{"text/plain":["tensor([[-0.0000,  5.6330,  7.8434, -9.3558],\n","        [-0.0000, -8.1764, -0.0000,  0.0000]], grad_fn=<SliceBackward0>)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["def my_init(m):\n","    if type(m) == nn.Linear:\n","        print(\"Init\", *[(name, param.shape)\n","                        for name, param in m.named_parameters()][0])\n","        nn.init.uniform_(m.weight, -10, 10)\n","        m.weight.data *= m.weight.data.abs() >= 5\n","\n","net.apply(my_init)\n","net[0].weight[:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1652217588330,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"LySwV5-513fo","outputId":"e77be333-01ae-4e04-c382-9f9bea225bae"},"outputs":[{"data":{"text/plain":["tensor([42.0000,  6.6330,  8.8434, -8.3558])"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["net[0].weight.data[:] += 1\n","net[0].weight.data[0, 0] = 42\n","net[0].weight.data[0]"]},{"cell_type":"markdown","metadata":{"id":"BOL8zVsK182q"},"source":["## 5.2.3. 参数绑定"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1652217605322,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"Pp6NfubJ16i1","outputId":"cde7b2f5-a570-4617-d0c0-7183ada101a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([True, True, True, True, True, True, True, True])\n","tensor([True, True, True, True, True, True, True, True])\n"]}],"source":["# 我们需要给共享层一个名称，以便可以引用它的参数\n","shared = nn.Linear(8, 8)\n","net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n","                    shared, nn.ReLU(),\n","                    shared, nn.ReLU(),\n","                    nn.Linear(8, 1))\n","net(X)\n","# 检查参数是否相同\n","print(net[2].weight.data[0] == net[4].weight.data[0])\n","net[2].weight.data[0, 0] = 100\n","# 确保它们实际上是同一个对象，而不只是有相同的值\n","print(net[2].weight.data[0] == net[4].weight.data[0])"]},{"cell_type":"markdown","metadata":{"id":"hM7wJ3jvzavi"},"source":["# 5.3. 延后初始化"]},{"cell_type":"markdown","metadata":{"id":"fIZXKZ2rzuDv"},"source":["## 5.3.1. 实例化网络"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRNw-iLD1-so"},"outputs":[],"source":["import tensorflow as tf\n","\n","net = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1652300927021,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"sZDi-Ct8zyLs","outputId":"01ab686a-de1e-49f7-a19f-3f218c51e308"},"outputs":[{"data":{"text/plain":["[[], []]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["[net.layers[i].get_weights() for i in range(len(net.layers))]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1652300940696,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"HOVbQ-nmz0ps","outputId":"f8a0688a-a365-421a-ef0a-195e24120b54"},"outputs":[{"data":{"text/plain":["[(20, 256), (256,), (256, 10), (10,)]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["X = tf.random.uniform((2, 20))\n","net(X)\n","[w.shape for w in net.get_weights()]"]},{"cell_type":"markdown","metadata":{"id":"bn0DXyLBz9_W"},"source":["# 5.4. 自定义层"]},{"cell_type":"markdown","metadata":{"id":"MVy5K3DA0BV0"},"source":["## 5.4.1. 不带参数的层"]},{"cell_type":"markdown","metadata":{"id":"O3y4MDduJOqx"},"source":["要构建它，我们只需继承基础层类并实现前向传播功能。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJXsGolBz4E6"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","\n","\n","class CenteredLayer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, X):\n","        return X - X.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1652301064136,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"Q8wmvt6D0GjQ","outputId":"006c5818-c0e0-4b79-a5ce-7b7d09644b9b"},"outputs":[{"data":{"text/plain":["tensor([-2., -1.,  0.,  1.,  2.])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["layer = CenteredLayer()\n","layer(torch.FloatTensor([1, 2, 3, 4, 5]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WD2TQ7Mt0WSz"},"outputs":[],"source":["net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1652301093991,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"MHLHVcIy0bIO","outputId":"6e048b09-ef39-4b40-a468-dac676248211"},"outputs":[{"data":{"text/plain":["tensor(1.8626e-09, grad_fn=<MeanBackward0>)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["Y = net(torch.rand(4, 8))\n","Y.mean()"]},{"cell_type":"markdown","metadata":{"id":"phonqfRh0gk-"},"source":["## 5.4.2. 带参数的层"]},{"cell_type":"markdown","metadata":{"id":"WId2n6-7JWUD"},"source":["现在，让我们实现自定义版本的全连接层。回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。在此实现中，我们使用修正线性单元作为激活函数。该层需要输入参数：in_units和units，分别表示输入数和输出数。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgKormZM0dlf"},"outputs":[],"source":["class MyLinear(nn.Module):\n","    def __init__(self, in_units, units):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.randn(in_units, units))\n","        self.bias = nn.Parameter(torch.randn(units,))\n","    def forward(self, X):\n","        linear = torch.matmul(X, self.weight.data) + self.bias.data\n","        return F.relu(linear)"]},{"cell_type":"markdown","metadata":{"id":"weqOGlupJalg"},"source":["接下来，我们实例化MyLinear类并访问其模型参数。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1652301172136,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"q9Dg1iUB0un1","outputId":"5fb56df4-2fe9-4aa5-be13-31f7168f0d96"},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[-0.9746, -0.8712, -0.1042],\n","        [-0.8893,  0.1659, -1.6141],\n","        [ 0.0546,  0.1851,  2.1352],\n","        [ 0.8160,  1.8363, -1.6074],\n","        [ 1.6919,  1.5625, -1.9794]], requires_grad=True)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["linear = MyLinear(5, 3)\n","linear.weight"]},{"cell_type":"markdown","metadata":{"id":"F2cY33mpJcxD"},"source":["我们可以使用自定义层直接执行前向传播计算。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1652301180560,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"GH8CNkgc0wr2","outputId":"81d034de-7492-4e31-8941-bd81d26c0f9e"},"outputs":[{"data":{"text/plain":["tensor([[1.1386, 0.0000, 0.0000],\n","        [3.0258, 0.1289, 0.0000]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["linear(torch.rand(2, 5))"]},{"cell_type":"markdown","metadata":{"id":"7boKQbjgJfLM"},"source":["我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1652301190903,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"XwGpE7wc0ywm","outputId":"4f794d20-aae9-4c9e-844f-eedca9f100fa"},"outputs":[{"data":{"text/plain":["tensor([[16.5141],\n","        [14.1852]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n","net(torch.rand(2, 64))"]},{"cell_type":"markdown","metadata":{"id":"Ae1YTZNZ05dB"},"source":["# 5.5. 读写文件"]},{"cell_type":"markdown","metadata":{"id":"mOUQiiHP09X0"},"source":["## 5.5.1. 加载和保存张量"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irthflOI01Qr"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","x = torch.arange(4)\n","torch.save(x, 'x-file')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1652301243927,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"e4pyUPeD1ASS","outputId":"04423489-7503-4c93-9aec-2641521e4e1c"},"outputs":[{"data":{"text/plain":["tensor([0, 1, 2, 3])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["x2 = torch.load('x-file')\n","x2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1652301257475,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"LCMTalmT1CP0","outputId":"530d3730-aac1-40b7-9c23-b4d1e14eabff"},"outputs":[{"data":{"text/plain":["(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y = torch.zeros(4)\n","torch.save([x, y],'x-files')\n","x2, y2 = torch.load('x-files')\n","(x2, y2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1652301268169,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"34pCv3Q_1FgT","outputId":"8f0bfeb0-e472-403e-cff6-934f844c0284"},"outputs":[{"data":{"text/plain":["{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["mydict = {'x': x, 'y': y}\n","torch.save(mydict, 'mydict')\n","mydict2 = torch.load('mydict')\n","mydict2"]},{"cell_type":"markdown","metadata":{"id":"IpZOtv6V1KtR"},"source":["## 5.5.2. 加载和保存模型参数"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scOiccvD1IKc"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden = nn.Linear(20, 256)\n","        self.output = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        return self.output(F.relu(self.hidden(x)))\n","\n","net = MLP()\n","X = torch.randn(size=(2, 20))\n","Y = net(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3e47kF_1RBU"},"outputs":[],"source":["torch.save(net.state_dict(), 'mlp.params')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1652301324537,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"MC9tTfdU1UI9","outputId":"2e0b9720-0c69-42a7-efde-d2100f8ca19e"},"outputs":[{"data":{"text/plain":["MLP(\n","  (hidden): Linear(in_features=20, out_features=256, bias=True)\n","  (output): Linear(in_features=256, out_features=10, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["clone = MLP()\n","clone.load_state_dict(torch.load('mlp.params'))\n","clone.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1652301332570,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"7zJN54CX1V5I","outputId":"2971e9c3-09fb-435b-8f6a-1302e3508621"},"outputs":[{"data":{"text/plain":["tensor([[True, True, True, True, True, True, True, True, True, True],\n","        [True, True, True, True, True, True, True, True, True, True]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["Y_clone = clone(X)\n","Y_clone == Y"]},{"cell_type":"markdown","metadata":{"id":"WLjGgxF11gSA"},"source":["# 5.6. GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1652301408530,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"QnlfRfnC1X3n","outputId":"9b5c5fde-2251-45e5-bb9c-60130f6895e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed May 11 20:36:48 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"l96j93-P1tyG"},"source":["## 5.6.1. 计算设备"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3261,"status":"ok","timestamp":1652301438384,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"_HiPjqEB1lmI","outputId":"1a949aae-1c80-4775-c7ee-e7be9158fca3"},"outputs":[{"data":{"text/plain":["(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torch import nn\n","\n","torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1652301449154,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"ITih348R1w1R","outputId":"01081131-6be8-47ac-e419-fa8448e04dae"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.device_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1652301471270,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"yBn4kurq10L4","outputId":"d8445c46-e674-4b90-b830-fa4dda98fd5d"},"outputs":[{"data":{"text/plain":["(device(type='cuda', index=0),\n"," device(type='cpu'),\n"," [device(type='cuda', index=0)])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def try_gpu(i=0):  \n","    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n","    if torch.cuda.device_count() >= i + 1:\n","        return torch.device(f'cuda:{i}')\n","    return torch.device('cpu')\n","\n","def try_all_gpus(): \n","    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n","    devices = [torch.device(f'cuda:{i}')\n","             for i in range(torch.cuda.device_count())]\n","    return devices if devices else [torch.device('cpu')]\n","\n","try_gpu(), try_gpu(10), try_all_gpus()"]},{"cell_type":"markdown","metadata":{"id":"LVwc6ZDj17-T"},"source":["## 5.6.2. 张量与GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1652301487013,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"dtAbC7MT13MV","outputId":"a92ac2b7-c08b-4f1b-cbab-88ace9bbea59"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1, 2, 3])\n","x.device"]},{"cell_type":"markdown","metadata":{"id":"j2FpifrC1_q0"},"source":["### 5.6.2.1. 存储在GPU上"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10559,"status":"ok","timestamp":1652301513839,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"wr2pDJZY19d8","outputId":"9e729288-cc0a-4d61-e0cc-49c3c6afede1"},"outputs":[{"data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], device='cuda:0')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["X = torch.ones(2, 3, device=try_gpu())\n","X"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1652301519392,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"xK51g86v2BgL","outputId":"eb0533be-7eb7-45bc-de49-2ab586214243"},"outputs":[{"data":{"text/plain":["tensor([[0.9387, 0.5419, 0.5454],\n","        [0.9719, 0.1203, 0.3608]], device='cuda:0')"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["Y = torch.rand(2, 3, device=try_gpu(0))\n","Y"]},{"cell_type":"markdown","metadata":{"id":"fIYhwIes2IJy"},"source":["### 5.6.2.2. 复制"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":336,"status":"ok","timestamp":1652301551401,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"NgTB7psP2FYE","outputId":"a09f3ba1-2a5d-4105-9792-febf7dfa942d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], device='cuda:0')\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.]], device='cuda:0')\n"]}],"source":["Z = X.cuda(0)\n","print(X)\n","print(Z)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430,"status":"ok","timestamp":1652301558411,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"71a-hB8A2Lwh","outputId":"2c9503a7-f524-41f1-cd2a-87bcaccf114e"},"outputs":[{"data":{"text/plain":["tensor([[1.9387, 1.5419, 1.5454],\n","        [1.9719, 1.1203, 1.3608]], device='cuda:0')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["Y + Z"]},{"cell_type":"markdown","metadata":{"id":"E5Cg0Gzs2SIp"},"source":["## 5.6.3. 神经网络与GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJmMhB4-2O7O"},"outputs":[],"source":["net = nn.Sequential(nn.Linear(3, 1))\n","net = net.to(device=try_gpu())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":938,"status":"ok","timestamp":1652301584430,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"wgzOo0XR2Tk6","outputId":"524de7e8-de74-4d5d-c089-f150ddf36362"},"outputs":[{"data":{"text/plain":["tensor([[0.1558],\n","        [0.1558]], device='cuda:0', grad_fn=<AddmmBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["net(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1652301589385,"user":{"displayName":"Shumeng Lin","userId":"11180216978862928857"},"user_tz":240},"id":"WGyyLwJb2VF4","outputId":"6a0b6e67-4f5c-41f8-c9ca-ef0503c28ade"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["net[0].weight.data.device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sz0yHEoI2Wel"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPGl7b2JDxlPMrVRjOdOKVc","collapsed_sections":[],"name":"5. 深度学习计算.ipynb","provenance":[]},"kernelspec":{"display_name":"pytorch_cpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"4e4c726780b780476faeccbedd2bcc7bfd06024dafd51abfdc0b7f98b66857d0"}}},"nbformat":4,"nbformat_minor":0}
